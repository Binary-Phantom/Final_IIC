# -*- coding: utf-8 -*-
"""Final IIC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YGUOeO1AEAcatoXSAfzc-za5no8J_Z8x

#IMPORTAÇÃO DE DEPENDÊNCIAS
"""

#import pandas as pd
st.set_option('server.maxMessageSize', 1000)
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neighbors import NearestNeighbors
#import numpy as np
from sklearn.metrics import accuracy_score
import sklearn.metrics.pairwise as pw
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
st.set_option('server.maxMessageSize', 1000)
#pip install fuzzywuzzy
#from fuzzywuzzy import process
#from fuzzywuzzy import fuzz

"""##Filmes"""

url = 'https://drive.google.com/file/d/11soEDwLvKtI6dR3-3OkUWyXnHqU-_0bP/view?usp=sharing'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
df_filme = pd.read_csv(url,sep=',')

"""##Notas"""

url = 'https://drive.google.com/file/d/1nrzhbmeK5OTEoqiCQ5lsayk8_q3FLnQc/view?usp=sharing'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
df_nota = pd.read_csv(url,sep=',')

"""##Dados"""

url = 'https://drive.google.com/file/d/1TayoFh9h-1Ghtk0Tm_LQWjqPyLlyJGzQ/view?usp=sharing'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
df_dados = pd.read_csv(url,sep=',')

"""##Tags"""

url = 'https://drive.google.com/file/d/1utKL4qufR0OmACaAeNubINH5n-Vkb4U2/view?usp=sharing'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
df_tag = pd.read_csv(url,sep=',')

#filmes = pd.read_csv("/content/drive/MyDrive/IIC/IIC Final/Dados.csv", sep="\t")
#nota = pd.read_csv("/content/drive/MyDrive/IIC/IIC Final/star.csv", sep="\t")

df_filme.head()

df_nota.head()

df_dados.head()

df_tag.head()

print("Colunas em df_nota:", df_nota.columns)

df_filme.shape

df_nota.shape

"""#LIMPEZA DE DADOS"""

duplicados = df_filme[df_filme.duplicated(keep='first')]
print(duplicados)

df_filme_set = set(df_filme['movieId'])
df_nota_set = set(df_nota['movieId'])

df_nota.drop_duplicates(subset ='movieId', keep='first', inplace=True)

"""#COMBINANDO DATAFRAMES"""

df_juntar = df_filme.merge(df_nota, on='movieId')
df_juntar.head()

filmes = pd.pivot_table(df_juntar, index='title', columns='userId', values='rating').fillna(0)
filmes.head()

"""#REMOÇÃO DE VALORES NULOS"""

rec = pw.cosine_similarity(filmes)
rec

rec_df = pd.DataFrame(rec, columns=filmes.index, index=filmes.index)
rec_df.head()

"""#Resultado obtido utilizando o Colaborative Filtering"""

cossine_df = pd.DataFrame(rec_df['Finding Nemo'].sort_values(ascending=False))
cossine_df.columns = ['Recomendações']
cossine_df.head(20)

df_dados.head()

df_tag.head()

"""#transformando movieId em inteiro"""

df_filme['movieId'] = df_filme['movieId'].apply(lambda x: str(x))

df_dados.shape

df_tag.shape

df2 = df_filme.merge(df_dados, left_on='title', right_on='Name', how='left')
df2 = df2.merge(df_tag, left_on='movieId', right_on='movieId', how='left')
df2['Infos'] = df2['genres'] + str(df2['Directors_Cast']) + str(df2['Discription']) + df2['tag']
df2.head()

vetor = TfidfVectorizer()
Tfidf = vetor.fit_transform(df2['Infos'].apply(lambda x: np.str_(x)))

similaridade = cosine_similarity(Tfidf)
similaridade

similaridade_df = pd.DataFrame(similaridade, columns=df2['title'], index=df2['title'])
similaridade_df.head ()

"""#Resultado obtido utilizando o Content-Based-Filtering"""

resultado_df = pd.DataFrame(similaridade_df['Finding Nemo'].sort_values(ascending=False))
resultado_df.columns = ['Recomendações']
resultado_df.head(30)

